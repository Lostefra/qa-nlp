{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItxFQ_AGrUNC",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# qa-nlp\n",
    "Question answering neural model based on the SQuAD dataset.\n",
    "\n",
    "Authors:\n",
    "- Lorenzo Mario Amorosa\n",
    "- Andrea Espis\n",
    "- Mattia Orlandi\n",
    "- Giacomo Pinardi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRQNkw-jrUNM"
   },
   "source": [
    "## 0. Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "va4wBPSvrUNN"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQzgf_JhrUNP",
    "outputId": "b8f75bee-4dc2-4f6d-c47c-e7259a2d7381"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nihil/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/nihil/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using this device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Library to read json\n",
    "import json\n",
    "\n",
    "# Numeric and data manipulation tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Deep learning framework\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Natural language tools\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "# Other tools\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import OrderedDict, Counter\n",
    "from time import time\n",
    "from itertools import zip_longest\n",
    "\n",
    "# automatic mixed precision training:\n",
    "from torch.cuda.amp import autocast \n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# Type hint\n",
    "from typing import Optional, Callable, Tuple, Dict, List, Union\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use GPU acceleration if possible\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using this device:', DEVICE)\n",
    "\n",
    "if not(torch.cuda.is_available()):\n",
    "    raise Exception('Switch to runtime GPU, otherwise the code won\\'t work properly')\n",
    "   \n",
    "# to avoid memory problems:\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Dy5Oi3yQrUNS"
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def fix_random(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_random(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fGjA5NMNrUNT",
    "outputId": "d37ca779-dc48-4227-ec8c-e3b8df31b7e5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "using this device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use GPU acceleration if possible\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using this device:\", DEVICE)\n",
    "\n",
    "# Define special tokens\n",
    "PAD = '<PAD>'\n",
    "UNK = '<UNK>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GbJ8fgEyrUNU"
   },
   "outputs": [],
   "source": [
    "# Lambda for computing the mean of a list\n",
    "mean: Callable[[List[float]], float] = lambda l: sum(l) / len(l)\n",
    "\n",
    "# Lambda for transforming a list of tuples into a tuple of lists\n",
    "to_tuple_of_lists: Callable[[List[Tuple]], Tuple[List]] = lambda list_of_tuples: tuple(map(list, zip(*list_of_tuples)))\n",
    "\n",
    "# Lambda for transforming a tuple of lists into a list of tuples\n",
    "to_list_of_tuples: Callable[[Tuple[List]], List[Tuple]] = lambda tuple_of_lists: list(zip(*tuple_of_lists))\n",
    "\n",
    "# Lambda for iterating with batches (if the length of the sequences does not match with the batch size, tuples of empty lists are appended)\n",
    "batch_iteration: Callable[[List[Tuple]], zip] = lambda data, batch_size: zip_longest(*[iter(data)] * batch_size, fillvalue=([], [], []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZPwLx1IrUNU"
   },
   "source": [
    "## 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "adXqWjOqrUNW",
    "outputId": "53d05a00-4666-499f-fabb-e1a81b7d3d4e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   paragraph_index  context_index  \\\n",
       "0                0              0   \n",
       "1                0              0   \n",
       "2                0              0   \n",
       "3                0              0   \n",
       "4                0              0   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "1  What is in front of the Notre Dame Main Building?   \n",
       "2  The Basilica of the Sacred heart at Notre Dame...   \n",
       "3                  What is the Grotto at Notre Dame?   \n",
       "4  What sits on top of the Main Building at Notre...   \n",
       "\n",
       "                         id  answer_start  answer_end  \\\n",
       "0  5733be284776f41900661182           515         541   \n",
       "1  5733be284776f4190066117f           188         213   \n",
       "2  5733be284776f41900661180           279         296   \n",
       "3  5733be284776f41900661181           381         420   \n",
       "4  5733be284776f4190066117e            92         126   \n",
       "\n",
       "                               answer_text  \n",
       "0               Saint Bernadette Soubirous  \n",
       "1                a copper statue of Christ  \n",
       "2                        the Main Building  \n",
       "3  a Marian place of prayer and reflection  \n",
       "4       a golden statue of the Virgin Mary  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>paragraph_index</th>\n      <th>context_index</th>\n      <th>question</th>\n      <th>id</th>\n      <th>answer_start</th>\n      <th>answer_end</th>\n      <th>answer_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>To whom did the Virgin Mary allegedly appear i...</td>\n      <td>5733be284776f41900661182</td>\n      <td>515</td>\n      <td>541</td>\n      <td>Saint Bernadette Soubirous</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>What is in front of the Notre Dame Main Building?</td>\n      <td>5733be284776f4190066117f</td>\n      <td>188</td>\n      <td>213</td>\n      <td>a copper statue of Christ</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n      <td>5733be284776f41900661180</td>\n      <td>279</td>\n      <td>296</td>\n      <td>the Main Building</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>What is the Grotto at Notre Dame?</td>\n      <td>5733be284776f41900661181</td>\n      <td>381</td>\n      <td>420</td>\n      <td>a Marian place of prayer and reflection</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>What sits on top of the Main Building at Notre...</td>\n      <td>5733be284776f4190066117e</td>\n      <td>92</td>\n      <td>126</td>\n      <td>a golden statue of the Virgin Mary</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "\"\"\"\n",
    "json structure:\n",
    "\n",
    "data []\n",
    "|---title\n",
    "|---paragraphs []\n",
    "|   |---context\n",
    "|   |---qas []\n",
    "|   |   |---answers []\n",
    "|   |   |   |---answer_start\n",
    "|   |   |   |---text\n",
    "|   |   |---question\n",
    "|   |   |---id\n",
    "version\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "filename = 'training_set.json'\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    raw_data = f.readlines()[0]\n",
    "\n",
    "parsed_data = json.loads(raw_data)['data']\n",
    "\n",
    "context_list = []\n",
    "context_index = -1\n",
    "paragraph_index = -1\n",
    "\n",
    "dataset = {'paragraph_index': [], 'context_index': [], 'question': [], 'id': [], 'answer_start': [], 'answer_end': [], 'answer_text': []}\n",
    "\n",
    "for i in range(len(parsed_data)):\n",
    "    paragraph_index += 1\n",
    "    for j in range(len(parsed_data[i]['paragraphs'])):\n",
    "        context_list.append(parsed_data[i]['paragraphs'][j]['context'])\n",
    "        context_index += 1\n",
    "\n",
    "        for k in range(len(parsed_data[i]['paragraphs'][j]['qas'])):\n",
    "            question = parsed_data[i]['paragraphs'][j]['qas'][k]['question']\n",
    "            id = parsed_data[i]['paragraphs'][j]['qas'][k]['id']\n",
    "\n",
    "            for l in range(len(parsed_data[i]['paragraphs'][j]['qas'][k]['answers'])): \n",
    "                answer_start = parsed_data[i]['paragraphs'][j]['qas'][k]['answers'][l]['answer_start']\n",
    "                answer_text = parsed_data[i]['paragraphs'][j]['qas'][k]['answers'][l]['text']\n",
    "\n",
    "                answer_end = answer_start + len(answer_text)\n",
    "\n",
    "                dataset['paragraph_index'].append(paragraph_index)\n",
    "                dataset['context_index'].append(context_index)\n",
    "                dataset['question'].append(question)\n",
    "                dataset['id'].append(id)\n",
    "                dataset['answer_start'].append(answer_start)\n",
    "                dataset['answer_end'].append(answer_end)\n",
    "                dataset['answer_text'].append(answer_text)\n",
    "\n",
    "df = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wdFLg01QrUNX",
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fur may be no less serious and heinous than genocide.\"\nQuestion: What has been widely debated as a possible act of genocide in Sudan? \n\nContext:  The majority of studies indicate antibiotics do interfere with contraceptive pills, such as clinical studies that suggest the failure rate of contraceptive pills caused by antibiotics is very low (about 1%). In cases where antibacterials have been suggested to affect the efficiency of birth control pills, such as for the broad-spectrum antibacterial rifampicin, these cases may be due to an increase in the activities of hepatic liver enzymes' causing increased breakdown of the pill's active ingredients. Effects on the intestinal flora, which might result in reduced absorption of estrogens in the colon, have also been suggested, but such suggestions have been inconclusive and controversial. Clinicians have recommended that extra contraceptive measures be applied during therapies using antibacterials that are suspected to interact with oral contraceptives.\nQuestion: What do antibiotics interfere with? \n\nContext:  Frédéric François Chopin (/ˈʃoʊpæn/; French pronunciation: ​[fʁe.de.ʁik fʁɑ̃.swa ʃɔ.pɛ̃]; 22 February or 1 March 1810 – 17 October 1849), born Fryderyk Franciszek Chopin,[n 1] was a Polish and French (by citizenship and birth of father) composer and a virtuoso pianist of the Romantic era, who wrote primarily for the solo piano. He gained and has maintained renown worldwide as one of the leading musicians of his era, whose \"poetic genius was based on a professional technique that was without equal in his generation.\" Chopin was born in what was then the Duchy of Warsaw, and grew up in Warsaw, which after 1815 became part of Congress Poland. A child prodigy, he completed his musical education and composed his earlier works in Warsaw before leaving Poland at the age of 20, less than a month before the outbreak of the November 1830 Uprising.\nQuestion: In what era of music did Chopin compose? \n\nContext:  Fryderyk may have had some piano instruction from his mother, but his first professional music tutor, from 1816 to 1821, was the Czech pianist Wojciech Żywny. His elder sister Ludwika also took lessons from Żywny, and occasionally played duets with her brother. It quickly became apparent that he was a child prodigy. By the age of seven Fryderyk had begun giving public concerts, and in 1817 he composed two polonaises, in G minor and B-flat major. His next work, a polonaise in A-flat major of 1821, dedicated to Żywny, is his earliest surviving musical manuscript.\nQuestion: How old was Chopin when he began to perform for the public? \n\nContext:  Chopin's successes as a composer and performer opened the door to western Europe for him, and on 2 November 1830, he set out, in the words of Zdzisław Jachimecki, \"into the wide world, with no very clearly defined aim, forever.\" With Woyciechowski, he headed for Austria, intending to go on to Italy. Later that month, in Warsaw, the November 1830 Uprising broke out, and Woyciechowski returned to Poland to enlist. Chopin, now alone in Vienna, was nostalgic for his homeland, and wrote to a friend, \"I curse the moment of my departure.\" When in September 1831 he learned, while travelling from Vienna to Paris, that the uprising had been crushed, he expressed his anguish in the pages of his private journal: \"Oh God! ... You are there, and yet you do not take vengeance!\" Jachimecki ascribes to these events the composer's maturing \"into an inspired national bard who intuited the past, present and future of his native Poland.\"\nQuestion: What geographicla region was opened for Chopin due to his composing and performances? \n\nContext:  In 1836, at a party hosted by Marie d'Agoult, Chopin met the French author George Sand (born [Amantine] Aurore [Lucile] Dupin). Short (under five feet, or 152 cm), dark, big-eyed and a cigar smoker, she initially repelled Chopin, who remarked, \"What an unattractive person la Sand is. Is she really a woman?\" However, by early 1837 Maria Wodzińska's mother had made it clear to Chopin in correspondence that a marriage with her daughter was unlikely to proceed. It is thought that she was influenced by his poor health and possibly also by rumours about his associations with women such as d'Agoult and Sand. Chopin finally placed the letters from Maria and her mother in a package on which he wrote, in Polish, \"My tragedy\". Sand, in a letter to Grzymała of June 1838, admitted strong feelings for the composer and debated whether to abandon a current affair in order to begin a relationship with Chopin; she asked Grzymała to assess Chopin's relationship with Maria Wodzińska, without realising that the affair, at least from Maria's side, was over.\nQuestion: What is the name of the author Chopin met at a gathering put on by Marie d'Agoult? \n\nContext:  Chopin's public popularity as a virtuoso began to wane, as did the number of his pupils, and this, together with the political strife and instability of the time, caused him to struggle financially. In February 1848, with the cellist Auguste Franchomme, he gave his last Paris concert, which included three movements of the Cello Sonata Op. 65.\nQuestion: Who did Chopin have at his last Parisian concert in 1848? \n\nContext:  With his health further deteriorating, Chopin desired to have a family member with him. In June 1849 his sister Ludwika came to Paris with her husband and daughter, and in September, supported by a loan from Jane Stirling, he took an apartment at Place Vendôme 12. After 15 October, when his condition took a marked turn for the worse, only a handful of his closest friends remained with him, although Viardot remarked sardonically that \"all the grand Parisian ladies considered it de rigueur to faint in his room.\"\nQuestion: Who accompanied Chopin's sister to Paris? \n\nContext:  Chopin's mazurkas and waltzes are all in straightforward ternary or episodic form, sometimes with a coda. The mazurkas often show more folk features than many of his other works, sometimes including modal scales and harmonies and the use of drone basses. However, some also show unusual sophistication, for example Op. 63 No. 3, which includes a canon at one beat's distance, a great rarity in music.\nQuestion: What does Chopin's Op. 63 No. 3 have that is rare? \n\nContext:  In 1207, the Mongol ruler Genghis Khan (r. 1206–1227) conquered and subjugated the ethnic Tangut state of the Western Xia (1038–1227). In the same year, he established diplomatic relations with Tibet by sending envoys there. The conquest of the Western Xia alarmed Tibetan rulers, who decided to pay tribute to the Mongols. However, when they ceased to pay tribute after Genghis Khan's death, his successor Ögedei Khan (r. 1229–1241) launched an invasion into Tibet.\nQuestion: Which ruler took Western Xia under their control? \n\nContext:  A. Tom Grunfeld says that Tsongkhapa claimed ill health in his refusal to appear at the Ming court, while Rossabi adds that Tsongkhapa cited the \"length and arduousness of the journey\" to China as another reason not to make an appearance. This first request by the Ming was made in 1407, but the Ming court sent another embassy in 1413, this one led by the eunuch Hou Xian (候顯; fl. 1403–1427), which was again refused by Tsongkhapa. Rossabi writes that Tsongkhapa did not want to entirely alienate the Ming court, so he sent his disciple Chosrje Shākya Yeshes to Nanjing in 1414 on his behalf, and upon his arrival in 1415 the Yongle Emperor bestowed upon him the title of \"State Teacher\"—the same title earlier awarded the Phagmodrupa ruler of Tibet. The Xuande Emperor (r. 1425–1435) even granted this disciple Chosrje Shākya Yeshes the title of a \"King\" (王). This title does not appear to have held any practical meaning, or to have given its holder any power, at Tsongkhapa's Ganden Monastery. Wylie notes that this—like the Karma Kargyu—cannot be seen as a reappointment of Mongol Yuan offices, since the Gelug school was created after the fall of the Yuan dynasty.\nQuestion: When was Chosrje Shākya Yeshes sent to Nanjing? \n\nContext:  China Daily, a CCP-controlled news organization since 1981, states in a 2008 article that although there were dynastic changes after Tibet was incorporated into the territory of Yuan dynasty's China in the 13th century, \"Tibet has remained under the jurisdiction of the central government of China.\" It also states that the Ming dynasty \"inherited the right to rule Tibet\" from the Yuan dynasty, and repeats the claims in the Mingshi about the Ming establishing two itinerant high commands over Tibet. China Daily states that the Ming handled Tibet's civil administration, appointed all leading officials of these administrative organs, and punished Tibetans who broke the law. The party-controlled People's Daily, the state-controlled Xinhua News Agency, and the state-controlled national television network China Central Television posted the same article that China Daily had, the only difference being their headlines and some additional text.\nQuestion: When was Tibet included into the territory of Yuan dynasty's China? \n\nContext:  In mid-2015, a new model of the iPod Touch was announced by Apple, and was officially released on the Apple store on July 15, 2015. The sixth generation iPod Touch includes a wide variety of spec improvements such as the upgraded A8 processor and higher-quality screen. The core is over 5 times faster than previous models and is built to be roughly on par with the iPhone 5S. It is available in 5 different colors: Space grey, pink, gold, silver and Product (red).\nQuestion: What type of processor does the current iPod Touch use? \n\nContext:  Some independent stereo manufacturers including JVC, Pioneer, Kenwood, Alpine, Sony, and Harman Kardon also have iPod-specific integration solutions. Alternative connection methods include adapter kits (that use the cassette deck or the CD changer port), audio input jacks, and FM transmitters such as the iTrip—although personal FM transmitters are illegal in some countries. Many car manufacturers have added audio input jacks as standard.\nQuestion: What type of transmitter is used in the iTrip? \n\nContext:  On August 24, 2006, Apple and Creative announced a broad settlement to end their legal disputes. Apple will pay Creative US$100 million for a paid-up license, to use Creative's awarded patent in all Apple products. As part of the agreement, Apple will recoup part of its payment, if Creative is successful in licensing the patent. Creative then announced its intention to produce iPod accessories by joining the Made for iPod program.\nQuestion: How much did Apple pay to Creative Technologies to settle their 2006 suit? \n\nContext:  The Legend of Zelda: Twilight Princess (Japanese: ゼルダの伝説 トワイライトプリンセス, Hepburn: Zeruda no Densetsu: Towairaito Purinsesu?) is an action-adventure game developed and published by Nintendo for the GameCube and Wii home video game consoles. It is the thirteenth installment in the The Legend of Zelda series. Originally planned for release on the GameCube in November 2005, Twilight Princess was delayed by Nintendo to allow its developers to refine the game, add more content, and port it to the Wii. The Wii version was released alongside the console in North America in November 2006, and in Japan, Europe, and Australia the following month. The GameCube version was released worldwide in December 2006.[b]\nQuestion: When was Twilight Princess launched in North America? \n\nContext:  Ganondorf then revives, and Midna teleports Link and Zelda outside the castle so she can hold him off with the Fused Shadows. However, as Hyrule Castle collapses, it is revealed that Ganondorf was victorious as he crushes Midna's helmet. Ganondorf engages Link on horseback, and, assisted by Zelda and the Light Spirits, Link eventually knocks Ganondorf off his horse and they duel on foot before Link strikes down Ganondorf and plunges the Master Sword into his chest. With Ganondorf dead, the Light Spirits not only bring Midna back to life, but restore her to her true form. After bidding farewell to Link and Zelda, Midna returns home before destroying the Mirror of Twilight with a tear to maintain balance between Hyrule and the Twilight Realm. Near the end, as Hyrule Castle is rebuilt, Link is shown leaving Ordon Village heading to parts unknown.\nQuestion: What does Midna destroy? \n\nContext:  Twilight Princess received the awards for Best Artistic Design, Best Original Score, and Best Use of Sound from IGN for its GameCube version. Both IGN and Nintendo Power gave Twilight Princess the awards for Best Graphics and Best Story. Twilight Princess received Game of the Year awards from GameTrailers, 1UP.com, Electronic Gaming Monthly, Game Informer, Games Radar, GameSpy, Spacey Awards, X-Play and Nintendo Power. It was also given awards for Best Adventure Game from the Game Critics Awards, X-Play, IGN, GameTrailers, 1UP.com, and Nintendo Power. The game was considered the Best Console Game by the Game Critics Awards and GameSpy. The game placed 16th in Official Nintendo Magazine's list of the 100 Greatest Nintendo Games of All Time. IGN ranked the game as the 4th-best Wii game. Nintendo Power ranked the game as the third-best game to be released on a Nintendo system in the 2000s decade.\nQuestion: What place did the game take in Nintendo's Official list of 100 Greatest Nintendo Games of All Time? \n\nContext:  Despite being an original story, Spectre draws on Ian Fleming's source material, most notably in the character of Franz Oberhauser, played by Christoph Waltz. Oberhauser shares his name with Hannes Oberhauser, a background character in the short story \"Octopussy\" from the Octopussy and The Living Daylights collection, and who is named in the film as having been a temporary legal guardian of a young Bond in 1983. Similarly, Charmian Bond is shown to have been his full-time guardian, observing the back story established by Fleming. With the acquisition of the rights to Spectre and its associated characters, screenwriters Neal Purvis and Robert Wade revealed that the film would provide a minor retcon to the continuity of the previous films, with the Quantum organisation alluded to in Casino Royale and introduced in Quantum of Solace reimagined as a division within Spectre rather than an independent organisation.\nQuestion: What is the name of the short story in which Hannes Oberhauser appeared? \n\nContext:  Thomas Newman returned as Spectre's composer. Rather than composing the score once the film had moved into post-production, Newman worked during filming. The theatrical trailer released in July 2015 contained a rendition of John Barry's On Her Majesty's Secret Service theme. Mendes revealed that the final film would have more than one hundred minutes of music. The soundtrack album was released on 23 October 2015 in the UK and 6 November 2015 in the USA on the Decca Records label.\nQuestion: Which record label was the soundtrack album released on? \n\nContext:  It is also known as the Wenchuan earthquake (Chinese: 汶川大地震; pinyin: Wènchuān dà dìzhèn; literally: \"Great Wenchuan earthquake\"), after the location of the earthquake's epicenter, Wenchuan County, Sichuan. The epicenter was 80 kilometres (50 mi) west-northwest of Chengdu, the provincial capital, with a focal depth of 19 km (12 mi). The earthquake was also felt in nearby countries and as far away as both Beijing and Shanghai—1,500 km (930 mi) and 1,700 km (1,060 mi) away—where office buildings swayed with the tremor. Strong aftershocks, some exceeding magnitude 6, continued to hit the area even months after the main quake, causing new casualties and damage.\nQuestion: What was the focal depth of the quake? \n\nContext:  All of the highways into Wenchuan, and others throughout the province, were damaged, resulting in delayed arrival of the rescue troops. In Beichuan County, 80% of the buildings collapsed according to Xinhua News. In the city of Shifang, the collapse of two chemical plants led to leakage of some 80 tons of liquid ammonia, with hundreds of people reported buried. In the city of Dujiangyan, south-east of the epicenter, a whole school collapsed with 900 students buried and fewer than 60 survived. The Juyuan Middle School, where many teenagers were buried, was excavated by civilians and cranes. Dujiangyan is home of the Dujiangyan Irrigation System, an ancient water diversion project which is still in use and is a UNESCO World Heritage Site. The project's famous Fish Mouth was cracked but not severely damaged otherwise.\nQuestion: What leaked liquid ammonia in Shifang? \n\nContext:  In the days following the disaster, an international reconnaissance team of engineers was dispatched to the region to make a detailed preliminary survey of damaged buildings. Their findings show a variety of reasons why many constructions failed to withstand the earthquake.\nQuestion: What did the team of engineers do? \n\nContext:  In 2002, Chinese geologist Chen Xuezhong published a Seismic Risk Analysis study in which he came to the conclusion that beginning with 2003, attention should be paid to the possibility of an earthquake with a magnitude of over 7.0 occurring in Sichuan region. He based his study on statistical correlation. That Sichuan is a seismically active area has been discussed for years prior to the quake, though few studies point to a specific date and time.\nQuestion: Who published a Seismic Risk Analysis Study? \n\nContext:  On the evening of May 18, CCTV-1 hosted a special four-hour program called The Giving of Love (simplified Chinese: 爱的奉献; traditional Chinese: 愛的奉獻), hosted by regulars from the CCTV New Year's Gala and round-the-clock coverage anchor Bai Yansong. It was attended by a wide range of entertainment, literary, business and political figures from mainland China, Hong Kong, Singapore and Taiwan. Donations of the evening totalled 1.5 billion Chinese Yuan (~US$208 million). Of the donations, CCTV gave the biggest corporate contribution at ¥50 million. Almost at the same time in Taiwan, a similarly themed programme was on air hosted by the sitting president Ma Ying-jeou. In June, Hong Kong actor Jackie Chan, who donated $1.57 million to the victims, made a music video alongside other artists entitled \"Promise\"; the song was composed by Andy Lau. The Artistes 512 Fund Raising Campaign, an 8-hour fundraising marathon, was held on June 1 in Hong Kong; it was attended by some 200 Sinosphere musicians and celebrities. In Singapore, MediaCorp Channel 8 hosted a 'live' programme 让爱川流不息 to raise funds for the victims.\nQuestion: How much did actor Jackie Chan donate? \n\nContext:  On May 15, 2008 Geoffery York of the Globeandmail.com reported that the shoddily constructed buildings are commonly called \"tofu buildings\" because builders cut corners by replacing steel rods with thin iron wires for concrete re-inforcement; using inferior grade cement, if any at all; and using fewer bricks than they should. One local was quoted in the article as saying that \"the supervising agencies did not check to see if it met the national standards.\"\nQuestion: What did builder's use in place of steel rods as re-inforcement? \n\nContext:  New York grew in importance as a trading port while under British rule in the early 1700s. It also became a center of slavery, with 42% of households holding slaves by 1730, more than any other city other than Charleston, South Carolina. Most slaveholders held a few or several domestic slaves, but others hired them out to work at labor. Slavery became integrally tied to New York's economy through the labor of slaves throughout the port, and the banks and shipping tied to the South. Discovery of the African Burying Ground in the 1990s, during construction of a new federal courthouse near Foley Square, revealed that tens of thousands of Africans had been buried in the area in the colonial years.\nQuestion: What was being built that resulted in the discovery of the African Burial Ground? \n\n"
     ]
    }
   ],
   "source": [
    "# Some examples of contexts and questions:\n",
    "for i in range(0, 4000, 100):\n",
    "    # print('Title:   ', title_list[df['title_index'][i]])\n",
    "    print('Context: ', context_list[df['context_index'][i]])\n",
    "    print('Question:', df['question'][i], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVvkIL6urUNY",
    "outputId": "7f99e12d-1083-446d-b826-30630b40d661"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of train paragraphs: 284\nNumber of validation paragraphs: 70\nNumber of test paragraphs: 88\n\nNumber of train samples: 57451\nNumber of validation samples: 12921\nNumber of test samples: 17227\n"
     ]
    }
   ],
   "source": [
    "# Define split ratios\n",
    "test_ratio = 0.2\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Build array of paragraphs indexes and shuffle them\n",
    "paragraph_indexes = df['paragraph_index'].unique()\n",
    "np.random.shuffle(paragraph_indexes)\n",
    "n_samples = len(paragraph_indexes)\n",
    "\n",
    "# Reserve indexes for test set\n",
    "test_size = int(test_ratio * n_samples)\n",
    "train_val_size = n_samples - test_size\n",
    "test_indexes = paragraph_indexes[-test_size:]\n",
    "# Reserve indexes for validation set\n",
    "val_size = int(val_ratio * train_val_size)\n",
    "train_size = train_val_size - val_size\n",
    "val_indexes = paragraph_indexes[-(test_size + val_size):-test_size]\n",
    "# Reserve indexes for training set\n",
    "train_indexes = paragraph_indexes[:train_size]\n",
    "\n",
    "assert train_size == len(train_indexes), 'Something went wrong with train set slicing'\n",
    "assert val_size == len(val_indexes), 'Something went wrong with val set slicing'\n",
    "assert test_size == len(test_indexes), 'Something went wrong with test set slicing'\n",
    "\n",
    "print('Number of train paragraphs:', train_size)\n",
    "print('Number of validation paragraphs:', val_size)\n",
    "print('Number of test paragraphs:', test_size)\n",
    "\n",
    "# Split dataframe\n",
    "df_train = df[np.in1d(df['paragraph_index'], train_indexes)]\n",
    "df_val = df[np.in1d(df['paragraph_index'], val_indexes)]\n",
    "df_test = df[np.in1d(df['paragraph_index'], test_indexes)]\n",
    "\n",
    "print('\\nNumber of train samples:', len(df_train))\n",
    "print('Number of validation samples:', len(df_val))\n",
    "print('Number of test samples:', len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Och7ZLyNrUNa"
   },
   "source": [
    "\n",
    "## 2. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XKib809brUNa",
    "outputId": "53c26d6f-6214-4f87-8b3a-0ddeaf3c1ad4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading GloVe model...\n",
      "\n",
      "Download completed.\n"
     ]
    }
   ],
   "source": [
    "print('Downloading GloVe model...')\n",
    "emb_dim = 50\n",
    "glove_model = gloader.load('glove-wiki-gigaword-' + str(emb_dim))\n",
    "print('\\nDownload completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    df_train = pd.concat([df_train , df_val], axis=0) \n",
    "    df_val = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xzChXGNrUNj",
    "outputId": "473f855f-6976-4ae1-c9e2-52984b904855"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tokenizing training corpus... [51.999 s]\n",
      "Tokenizing validation corpus... [13.527 s]\n",
      "Tokenizing test corpus... [12.769 s]\n",
      "--------------------------------------------------\n",
      "Words in training set: 114839\n",
      "Words in validation set: 131821\n",
      "Words in test set: 131821\n"
     ]
    }
   ],
   "source": [
    "def tokenize_corpus(df: pd.DataFrame, context_list: List[str]):\n",
    "    twt = TreebankWordTokenizer()\n",
    "    \n",
    "    t_start = time()\n",
    "    # Retrieve contexts\n",
    "    contexts = df['context_index'].apply(lambda x: context_list[x])\n",
    "    # Tokenize both contexts and queries\n",
    "    x_ctx = contexts.apply(lambda x: twt.tokenize(x)).tolist()\n",
    "    x_qry = df['question'].apply(lambda x: twt.tokenize(x)).tolist()\n",
    "    # Get indexes to start_end characters\n",
    "    y_char = [(start, end) for start, end in zip(df['answer_start'].tolist(), df['answer_end'].tolist())]\n",
    "    # Get spans of tokens\n",
    "    spans_list = contexts.apply(lambda x: twt.span_tokenize(x)).tolist()\n",
    "    # Convert indexes s.t. the point to start/end tokens\n",
    "    y = []\n",
    "    for spans, (char_start, char_end) in zip(spans_list, y_char):\n",
    "        token_start, token_end = None, None\n",
    "        for i, span in enumerate(spans):\n",
    "            if span[0] <= char_start <= span[1]:\n",
    "                token_start = i\n",
    "            if span[0] <= char_end <= span[1]:\n",
    "                token_end = i\n",
    "        y.append((token_start, token_end))\n",
    "    print(f'[{time() - t_start:.3f} s]')\n",
    "    \n",
    "    return x_ctx, x_qry, y\n",
    "\n",
    "def build_vocabulary(corpus: List[List[str]],\n",
    "                     old_word_listing: Optional[List[str]] = None) -> (Dict[int, str], Dict[int, str], List[str]):\n",
    "    flat_tokens = [x for sub in corpus for x in sub]\n",
    "    \n",
    "    if old_word_listing is None:  # standard case\n",
    "        word_listing = [PAD] + list(OrderedDict.fromkeys(flat_tokens))\n",
    "    else:  # case in which we extend an already existing vocabulary\n",
    "        word_listing = list(OrderedDict.fromkeys(old_word_listing + flat_tokens))\n",
    "        \n",
    "    idx_to_word = {i: w for i, w in enumerate(word_listing)}\n",
    "    word_to_idx = {w: i for i, w in enumerate(word_listing)}\n",
    "\n",
    "    return idx_to_word, word_to_idx, word_listing\n",
    "\n",
    "# Tokenize corpus\n",
    "print('Tokenizing training corpus...', end=' ')\n",
    "X_trainC, X_trainQ, Y_train = tokenize_corpus(df_train, context_list)\n",
    "train_corpus = X_trainC + X_trainQ\n",
    "\n",
    "print('Tokenizing validation corpus...', end=' ')\n",
    "X_valC, X_valQ, Y_val = tokenize_corpus(df_val, context_list)\n",
    "val_corpus = X_valC + X_valQ\n",
    "\n",
    "print('Tokenizing test corpus...', end=' ')\n",
    "X_testC, X_testQ, Y_test = tokenize_corpus(df_test, context_list)\n",
    "test_corpus = X_testC + X_testQ\n",
    "\n",
    "# Get word and char mappings for each set\n",
    "train_i2w, train_w2i, train_wl = build_vocabulary(train_corpus)\n",
    "val_i2w, val_w2i, val_wl = build_vocabulary(val_corpus, train_wl)\n",
    "test_i2w, test_w2i, test_wl = build_vocabulary(test_corpus, val_wl)\n",
    "\n",
    "print('-' * 50)\n",
    "print('Words in training set:', len(train_wl))\n",
    "print('Words in validation set:', len(val_wl))\n",
    "print('Words in test set:', len(test_wl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "fWxVpUV4rUNk",
    "outputId": "2e9b6eaf-05f9-4c86-8f68-4b635fc5fcbb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Saint', 'Bernadette']\n['To', 'whom', 'did', 'the', 'Virgin', 'Mary', 'allegedly', 'appear', 'in', '1858', 'in', 'Lourdes', 'France', '?']\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "\n",
    "print(X_trainC[x][Y_train[x][0]:Y_train[x][1]])\n",
    "print(X_trainQ[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2iq4-OXrUNm",
    "outputId": "27d3864b-9354-47c0-9be8-ebca165dd686"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total OOV terms in training set: 72875 (63.46%)\nTotal OOV terms in validation set: 85981 (65.23%)\nTotal OOV terms in test set: 85981 (65.23%)\n"
     ]
    }
   ],
   "source": [
    "train_oov_words = [word for word in train_wl if word not in glove_model.vocab and word != PAD]\n",
    "val_oov_words = [word for word in val_wl if word not in glove_model.vocab and word != PAD]\n",
    "test_oov_words = [word for word in test_wl if word not in glove_model.vocab and word != PAD]\n",
    "\n",
    "print(f'Total OOV terms in training set: {len(train_oov_words)} ({float(len(train_oov_words)) / len(train_wl) * 100:.2f}%)')\n",
    "print(f'Total OOV terms in validation set: {len(val_oov_words)} ({float(len(val_oov_words)) / len(val_wl) * 100:.2f}%)')\n",
    "print(f'Total OOV terms in test set: {len(test_oov_words)} ({float(len(test_oov_words)) / len(test_wl) * 100:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69,
     "referenced_widgets": [
      "4a48f25aef0f475fbae1944fbf9a4d05",
      "ef3d223156da417d92125c64b4c15764",
      "4dbc27e6aef24580b9aa7c78386133c8",
      "0bd6509fd092475089975b43065992dd",
      "75c212b98d6d4eaea9deb68623d4d859",
      "f5d5bdf4c71e4d78a37e7bf24f3c2723",
      "d65a5a8f8dd7443baee8d268f2265cbe",
      "e920fa8938da488aa7341ff02ea3336b",
      "0d95617ece614abbb4d46b672bb9687d",
      "08539714529945e89b53eab0ac97b32f",
      "94c61c9a1afc4d1a810f57b678ea5d8c",
      "8a8e0c6344174c0e82b4a6f11d38a20c",
      "e8d4c75c65ab49208d7837b4b8721db5",
      "2f4049cce26948a7936965eac7644dd4",
      "7bba134079cf4465b3c5df28452c2cde",
      "2069ac0814074778bbc0df17f73c28be",
      "636ac053b5dc498ca449c119d9ef9135",
      "43d75ca086e44329b0a00d4c4272b78e",
      "7ab9cc7d5ff648c7a24cbb92a5982a4b",
      "7f0ee4bb7bc2439495d6568f2337c460",
      "68649099ea1540058a383a0fd22650f0",
      "9c88edb55a7443ec84d58cf920823ebc",
      "eb3a3002e9b74d258b276824d215c465",
      "be6e59d759fd47909dc6b1705bb7d03a",
      "b432b77c9bc243fc97f15a5b843d76d8",
      "53635f370ae047d7be069cf8cb322dd2",
      "ecc1c611a9f445be8386c6078ba2f2b6",
      "73eac1d1a3fb423fb3f43c7ddd85db8f",
      "fb0a5046440f4af4a5e339cd6edcf0d0",
      "c5ba907b448b47609ed8ffc5e0486320",
      "83833eeed95b4a3d834cbd357c18a8bf",
      "0e920d8c41974bdfac1d58fb46cf71ba",
      "edda3abe1a4b4eaa853539f3a62b0e61",
      "8ee21f1c0ac64447974a90da531497cc",
      "f71ae15e051e4f719c79d247e3465324",
      "74aa40cf109f4b6ebf7e2ef677e2c40d",
      "abad7cb634924003be6e261593ba4c19",
      "8952810a0e2e4383ba656e6310c29710",
      "e60e3d7789bd4bb19f5652254048999a",
      "1c1da5ccfc914b28b5a800e82aec22de",
      "e490f93cd74141679e29d16bbe300e74",
      "415df3189aca4408b4a526fb7109ca11",
      "ddf2a13c15a2417e9d87b66d02604519",
      "825afd3ab8404f0e92a4d38367db8427",
      "a7fef9d40b9444e2866e33b02fb9dce5",
      "c2da6ccaedc34c428d2f7659d32816b9",
      "3a9342199b414592b74613ff84a3e884",
      "5ad0c0f15c214df4b0133928f5cde58e"
     ]
    },
    "id": "vmoaacExrUNm",
    "outputId": "43ef3b74-45e4-41c1-9413-a31a2bb031bd"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=114839.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da5d2254f5e14b628446cd627aa6cd49"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=114839.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ef09cb374034bcc9a5b6c1911b30d38"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of word embedding matrix (training set): (114839, 50)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=131821.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2c7a9045c36474cb8f8e9b9fc91c8eb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=131821.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab5efd7007af4897b2ca28c8167292c5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of word embedding matrix (validation set): (131821, 50)\n"
     ]
    }
   ],
   "source": [
    "def build_word_embedding_matrix(embedding_model: gensim.models.keyedvectors.Word2VecKeyedVectors,\n",
    "                                word_to_idx: Dict[str, int],\n",
    "                                oov_words: List[str],\n",
    "                                old_word_embedding_matrix: Optional[np.ndarray] = None):\n",
    "    # Initialize embedding matrix with all zeros\n",
    "    embedding_matrix = np.zeros((len(word_to_idx), embedding_model.vector_size))\n",
    "    \n",
    "    # Analyze embeddings to get mean and standard deviation\n",
    "    mean_list, std_list = [], []\n",
    "    for word in tqdm(word_to_idx.keys(), leave=False):\n",
    "        if word not in oov_words and word != PAD:\n",
    "            embed = embedding_model[word]\n",
    "            # Compute mean and std\n",
    "            mean_list.append(np.mean(embed))\n",
    "            std_list.append(np.std(embed))\n",
    "\n",
    "    embedding_mean = mean(mean_list)\n",
    "    embedding_std = mean(std_list)\n",
    "\n",
    "    for word, idx in tqdm(word_to_idx.items(), leave=False):\n",
    "        # If word is PAD no action is performed (it will be assigned the zero vector)\n",
    "        if word not in oov_words and word != PAD:\n",
    "            embedding_matrix[idx] = embedding_model[word]\n",
    "        elif word in oov_words:\n",
    "            oov_idx = word_to_idx[word]\n",
    "            if old_word_embedding_matrix is None or oov_idx >= len(old_word_embedding_matrix):\n",
    "                embedding_matrix[idx] = np.random.normal(loc=embedding_mean, scale=embedding_std, size=embedding_model.vector_size)\n",
    "            else:\n",
    "                embedding_matrix[idx] = old_word_embedding_matrix[oov_idx]\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "# Build word embedding matrix based only on the training set (for training)\n",
    "train_emb_mtx = build_word_embedding_matrix(glove_model, train_w2i, train_oov_words)\n",
    "print('Shape of word embedding matrix (training set):', train_emb_mtx.shape)\n",
    "\n",
    "# Build word embedding matrix based on training + validation set (for validation)\n",
    "val_emb_mtx = build_word_embedding_matrix(glove_model, val_w2i, val_oov_words, train_emb_mtx)\n",
    "print('Shape of word embedding matrix (validation set):', val_emb_mtx.shape)\n",
    "\n",
    "# Build word embedding matrix based on training + validation + test set (for test)\n",
    "#test_emb_mtx = build_word_embedding_matrix(glove_model, test_w2i, test_oov_words, val_emb_mtx)\n",
    "#print('Shape of word embedding matrix (test set):', test_emb_mtx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bM8RU5dWrUNm",
    "outputId": "fbeadd40-dc32-43d0-a5dc-9c6219cd68f5"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of char embedding matrix (training set): (101, 100)\n"
     ]
    }
   ],
   "source": [
    "def build_char_embedding_matrix(corpus: List[str],\n",
    "                                enc_dim: Optional[int] = 100):\n",
    "    # Flatten to obtain single characters\n",
    "    flat_chars = [c for sent in corpus for word in sent for c in word]\n",
    "    \n",
    "    # Sort characters by occurrences\n",
    "    unique_chars = Counter(flat_chars)\n",
    "    char_listing = sorted(unique_chars, key=unique_chars.get, reverse=True)\n",
    "    # Select only the enc_dim most frequent ones\n",
    "    if len(char_listing) > enc_dim - 1:\n",
    "        char_listing = char_listing[:enc_dim - 1]\n",
    "    char_listing = [PAD] + char_listing + [UNK]  # add PAD and UNK tokens\n",
    "    \n",
    "    idx_to_char = {i: c for i, c in enumerate(char_listing)}\n",
    "    char_to_idx = {c: i for i, c in enumerate(char_listing)}\n",
    "    \n",
    "    # Create one-hot vectors, reserving the last one for UNK (0...0, 1)\n",
    "    one_hot_chars = np.zeros((len(char_listing) - 1, enc_dim))\n",
    "    np.fill_diagonal(one_hot_chars, 1)\n",
    "    one_hot_chars = np.vstack([np.zeros((1, enc_dim)), one_hot_chars])  # stack zero vector on top for PAD\n",
    "    \n",
    "    return idx_to_char, char_to_idx, char_listing, one_hot_chars\n",
    "\n",
    "# Build char embedding matrix based only on the training set, and use it for validation and test too:\n",
    "# in fact, we can assume that characters appear uniformly in the three splits;\n",
    "# for those rare case in which this does not happen, we assign the UNK vector\n",
    "i2c, c2i, cl, char_emb_mtx = build_char_embedding_matrix(train_corpus)\n",
    "print('Shape of char embedding matrix (training set):', char_emb_mtx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j0vL1w4rUNn"
   },
   "source": [
    "## 3. Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "id": "je4uXafprUNn",
    "outputId": "f897ff3c-5c37-46ec-c7f0-83f4c78b0f4f"
   },
   "outputs": [],
   "source": [
    "from utils.bidaf_train_utils import training_loop\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_history(history):    \n",
    "    # this function is simply used to plot and save the image (and the dictionary) about the train and val loss and accuracy during the training\n",
    "    \n",
    "    \n",
    "    fig1, axes = plt.subplots(nrows=1, ncols=1, figsize=(7.5, 5))\n",
    "    plt.suptitle('loss', size='xx-large')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.])\n",
    "\n",
    "    axes.plot(history['loss'], label='train_loss')\n",
    "    axes.plot(history['val_loss'], label='val_loss')\n",
    "    axes.set_title('loss')\n",
    "    axes.set(xlabel='# Epochs')\n",
    "    axes.grid()\n",
    "    axes.legend();\n",
    "\n",
    "    fig2, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "    plt.suptitle('scores', size='xx-large')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    axes[0].plot(history['exact_score'], label='train_exact_score')\n",
    "    axes[0].plot(history['val_exact_score'], label='val_exact_score')\n",
    "    axes[0].set_title('exact_score')\n",
    "    axes[0].set(xlabel='# Epochs')\n",
    "    axes[0].grid()\n",
    "    axes[0].legend();\n",
    "\n",
    "    axes[1].plot(history['f1_score'], label='train_f1_score')\n",
    "    axes[1].plot(history['val_f1_score'], label='val_f1_score')\n",
    "    axes[1].set_title('f1_score')\n",
    "    axes[1].set(xlabel='# Epochs')\n",
    "    axes[1].grid()\n",
    "    axes[1].legend();\n",
    "    \n",
    "    fig3, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 5))\n",
    "    plt.suptitle('distances', size='xx-large')\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    axes[0].plot(history['distance_end'], label='train_distance_end')\n",
    "    axes[0].plot(history['val_distance_end'], label='val_distance_end')\n",
    "    axes[0].set_title('distance_end')\n",
    "    axes[0].set(xlabel='# Epochs')\n",
    "    axes[0].grid()\n",
    "    axes[0].legend();\n",
    "\n",
    "    axes[1].plot(history['distance_start'], label='train_distance_start')\n",
    "    axes[1].plot(history['val_distance_start'], label='val_distance_start')\n",
    "    axes[1].set_title('distance_start')\n",
    "    axes[1].set(xlabel='# Epochs')\n",
    "    axes[1].grid()\n",
    "    axes[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USINcfvurUNn"
   },
   "source": [
    "# jojonki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "A9pu_pkJrUNo"
   },
   "outputs": [],
   "source": [
    "# clear gpu memory before another training:\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "9XSaym8YrUNp"
   },
   "outputs": [],
   "source": [
    "from model.bidaf import BiDAF\n",
    "from model.char_embedder import CharEmbedder\n",
    "from model.word_embedder import WordEmbedder\n",
    "from model.tensor_maker import TensorMaker\n",
    "\n",
    "char_embedder = CharEmbedder(init_emb = torch.FloatTensor(char_emb_mtx),\n",
    "                             out_char_emb_dim = emb_dim,\n",
    "                             hidden_dim = 64,\n",
    "                             input_channels = 1,\n",
    "                             output_channels = 100,\n",
    "                             kernel_height = 5,\n",
    "                             trainable = False)\n",
    "# char_embedder = CharEmbedder(c_embd_size = 8, vocab_size_c = len(c2i), out_chs = 100, filters = [[1, 5]])\n",
    "\n",
    "train_word_embedder = WordEmbedder(init_emb = torch.FloatTensor(train_emb_mtx))\n",
    "val_word_embedder = WordEmbedder(init_emb = torch.FloatTensor(val_emb_mtx))\n",
    "\n",
    "# model_bidaf = BiDAF(char_embedder, train_word_embedder, val_word_embedder, use_constraint = True).to(DEVICE)\n",
    "\n",
    "#train_tensor_maker = TensorMaker(train_w2i, c2i, device=DEVICE)\n",
    "val_tensor_maker = TensorMaker(val_w2i, c2i, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BiDAF(\n",
       "  (char_embedder): CharEmbedder(\n",
       "    (embedding): Embedding(101, 100)\n",
       "    (conv_layer): Conv2d(1, 100, kernel_size=(5, 100), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "    (fc1): Linear(in_features=100, out_features=64, bias=False)\n",
       "    (fc2): Linear(in_features=64, out_features=50, bias=False)\n",
       "  )\n",
       "  (train_word_embedder): WordEmbedder(\n",
       "    (embedding): Embedding(114839, 50)\n",
       "  )\n",
       "  (eval_word_embedder): WordEmbedder(\n",
       "    (embedding): Embedding(131821, 50)\n",
       "  )\n",
       "  (highway_net): ConvolutionalHighwayNetwork(\n",
       "    (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (gate1): Conv2d(1, 1, kernel_size=(5, 100), stride=(1, 1), padding=(2, 0))\n",
       "    (conv2): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (gate2): Conv2d(1, 1, kernel_size=(5, 100), stride=(1, 1), padding=(2, 0))\n",
       "  )\n",
       "  (ctx_rnn): GRU(100, 100, batch_first=True, bidirectional=True)\n",
       "  (w_s): Linear(in_features=600, out_features=1, bias=False)\n",
       "  (mod_rnn): GRU(800, 100, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (w_p_start): Linear(in_features=1000, out_features=1, bias=False)\n",
       "  (p_end_rnn): GRU(201, 100, batch_first=True, bidirectional=True)\n",
       "  (w_p_end): Linear(in_features=1000, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Import from pickle files\n",
    "#char_embedder: CharEmbedder = None\n",
    "#with open(os.path.join('best_model', 'char_emb2.pickle'), 'rb') as f:\n",
    "#    char_embedder = pickle.load(f)\n",
    "#train_word_embedder: WordEmbedder = None\n",
    "#with open(os.path.join('best_model', 'train_word_embedder.pickle'), 'rb') as f:\n",
    "#    train_word_embedder = pickle.load(f)\n",
    "#val_word_embedder: WordEmbedder = None\n",
    "#with open(os.path.join('best_model', 'val_word_embedder.pickle'), 'rb') as f:\n",
    "#    val_word_embedder = pickle.load(f)\n",
    "\n",
    "# Create model\n",
    "model_bidaf = BiDAF(char_embedder, train_word_embedder, val_word_embedder, use_constraint=True, use_dropout=False).to(DEVICE)\n",
    "# Load the model state\n",
    "model_bidaf.load_state_dict(torch.load(os.path.join('best_model', 'bidaf_test.pt')))\n",
    "model_bidaf.eval()\n",
    "# Load tensor maker\n",
    "#tensor_maker = None\n",
    "#with open(os.path.join('best_model', 'tensor_maker.pickle'), 'rb') as f:\n",
    "#    tensor_maker = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4307.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c46620706705467bae4a840c22dca280"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start (p): 101, End (p): 102, Start (T): 49, End (T): 52\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3.46501502778017,\n",
       " 10.017240378475648,\n",
       " 10.489638358390899,\n",
       " 0.42061879607592734,\n",
       " 0.5999495749533893)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "from utils.bidaf_train_utils import evaluate\n",
    "from utils.squad_utils import squad_loss\n",
    "\n",
    "val_data = to_list_of_tuples((X_valC, X_valQ, Y_val))\n",
    "evaluate(model_bidaf, val_data, 4, squad_loss, val_tensor_maker, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "train_word_embedder = WordEmbedder(init_emb = torch.FloatTensor(train_emb_mtx))\n",
    "val_word_embedder = WordEmbedder(init_emb = torch.FloatTensor(val_emb_mtx))\n",
    "\n",
    "with open('char_emb2.pickle', 'wb') as f:\n",
    "    pickle.dump(char_embedder, f)\n",
    "#with open('train_word_embedder.pickle', 'wb') as f:\n",
    "#    pickle.dump(train_word_embedder, f)\n",
    "#with open('val_word_embedder.pickle', 'wb') as f:\n",
    "#    pickle.dump(val_word_embedder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui_FUciGrUNp",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.squad_utils import squad_loss\n",
    "from utils.bidaf_train_utils import training_loop\n",
    "\n",
    "train_data = to_list_of_tuples((X_trainC, X_trainQ, Y_train))\n",
    "val_data = to_list_of_tuples((X_valC, X_valQ, Y_val))\n",
    "\n",
    "EP = 5\n",
    "BS = 8\n",
    "\n",
    "#optimizer = torch.optim.Adam(model_bidaf.parameters(), lr=5e-3)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_bidaf.parameters()))\n",
    "#optimizer = torch.optim.Adadelta(model_bidaf.parameters(), lr=0.5, rho=0.999, eps=1e-06, weight_decay=0) # slower in time and in loss\n",
    "criterion = squad_loss\n",
    "\n",
    "\n",
    "history_noconst_jojonki_nohigh_1k = training_loop(model=model_bidaf,\n",
    "                        train_data=train_data,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=EP,\n",
    "                        batch_size=BS,\n",
    "                        criterion=criterion,\n",
    "                        train_tensor_maker=train_tensor_maker,\n",
    "                        val_tensor_maker=val_tensor_maker,\n",
    "                        val_data=val_data,\n",
    "                        early_stopping=True,\n",
    "                        patience = 15,\n",
    "                        checkpoint_path='bidaf_gru_noconstraint.pt',\n",
    "                        mix_scale = True)\n",
    "\n",
    "# eps =1e-7, #jojonki, # use_constraint, # BS = 8, #1ktrain, 3kval, lr=5e-3, patience = 30, EP = 50, emb = 100\n",
    "# adam optimizer # train+val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uq8ZMRMurUNq",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history(history_noconst_jojonki_nohigh_1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iaFU-kvFrUNq"
   },
   "source": [
    "# our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "aue6E-tSrUNq"
   },
   "outputs": [],
   "source": [
    "# clear gpu memory before another training:\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "RucVq3VxrUNr"
   },
   "outputs": [],
   "source": [
    "from model.bidaf import BiDAF\n",
    "from model.char_embedder import CharEmbedder\n",
    "from model.word_embedder import WordEmbedder\n",
    "from model.tensor_maker import TensorMaker\n",
    "\n",
    "char_embedder = CharEmbedder(init_emb = torch.FloatTensor(char_emb_mtx),\n",
    "                             out_char_emb_dim = emb_dim,\n",
    "                             hidden_dim = 64,\n",
    "                             input_channels = 1,\n",
    "                             output_channels = 100,\n",
    "                             kernel_height = 5,\n",
    "                             trainable = False)\n",
    "\n",
    "train_word_embedder = WordEmbedder(init_emb = torch.FloatTensor(train_emb_mtx))\n",
    "val_word_embedder = WordEmbedder(init_emb = torch.FloatTensor(val_emb_mtx))\n",
    "model_bidaf = BiDAF(char_embedder, train_word_embedder, val_word_embedder, use_constraint = True, use_dropout = False).to(DEVICE)\n",
    "train_tensor_maker = TensorMaker(train_w2i, c2i, device=DEVICE)\n",
    "val_tensor_maker = TensorMaker(val_w2i, c2i, device=DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605,
     "referenced_widgets": [
      "d9b249d0569c4463a01b2f4e9613266f",
      "4ee4c46636de4a62852f436939881519",
      "a2f112a8eb40404abcd9ee035e65fec9",
      "84dca6a666244fd2bf0760567d2e9c9c",
      "c61c126366334f5382fac34f45f0fde9",
      "495381cf2be845bba2b305e31b571cf2",
      "1ba47209576c4387a902abc5b0dbe180",
      "8578c2da68c44971a4869a5e37a3d171"
     ]
    },
    "id": "X4aoEiT2rUNr",
    "outputId": "ae75bcb6-0ccd-4942-8967-6f8fcf7a3589",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b249d0569c4463a01b2f4e9613266f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-c5dfd6c7fa22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0mpatience\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bidaf_gru_constraint.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                         mix_scale = True)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# p_end > p_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/utils/bidaf_train_utils.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_data, optimizer, epochs, batch_size, criterion, train_tensor_maker, val_tensor_maker, lr_scheduler, val_data, early_stopping, patience, tolerance, checkpoint_path, verbose, seed, mix_scale)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         train_loss, train_distance_start, train_distance_end, exact_score, f1_score = train(model, train_data, batch_size, criterion,\n\u001b[0;32m--> 241\u001b[0;31m                                                                      optimizer, train_tensor_maker, verbose, scaler)\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/utils/bidaf_train_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data, batch_size, criterion, optimizer, tensor_maker, verbose, scaler)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mcontext_word_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_char_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mquery_word_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_char_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mlabels_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mlabels_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type NoneType)"
     ]
    }
   ],
   "source": [
    "from utils.squad_utils import squad_loss\n",
    "from utils.bidaf_train_utils import training_loop\n",
    "\n",
    "train_data = to_list_of_tuples((X_trainC, X_trainQ, Y_train))\n",
    "val_data = to_list_of_tuples((X_valC, X_valQ, Y_val))\n",
    "\n",
    "EP = 5\n",
    "BS = 8\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model_bidaf.parameters()))\n",
    "# optimizer = torch.optim.Adam(model_bidaf.parameters(), lr=5e-3)\n",
    "# optimizer = torch.optim.Adadelta(model_bidaf.parameters(), lr=0.5, rho=0.999, eps=1e-06, weight_decay=0) # slower in time and in loss\n",
    "criterion = squad_loss\n",
    "\n",
    "history_drop = training_loop(model=model_bidaf,\n",
    "                        train_data=train_data,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=EP,\n",
    "                        batch_size=BS,\n",
    "                        criterion=criterion,\n",
    "                        train_tensor_maker=train_tensor_maker,\n",
    "                        val_tensor_maker=val_tensor_maker,\n",
    "                        val_data=val_data,\n",
    "                        early_stopping=True,\n",
    "                        patience = 15,\n",
    "                        checkpoint_path='bidaf_gru_constraint.pt',\n",
    "                        mix_scale = True)\n",
    "\n",
    "# p_end > p_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Jd0Dk6I08M-c"
   },
   "outputs": [],
   "source": [
    "torch.save(model_bidaf, \"bidaf_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-C2kr7dlrUNs",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history(history_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksmi0edirUNs"
   },
   "source": [
    "# to do :\n",
    "\n",
    "- dropout\n",
    "- explanation for bad results: BS too small\n",
    "- our model: trainable embedder = True\n",
    "- torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "- propose distance as new metric (normalized wrt the number of characters in the context)\n",
    "\n",
    "\n",
    "\n",
    "our takes 2 hours per epoch\n",
    "\n",
    "jojonki takes \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "qa-nlp_bidaf.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python385jvsc74a57bd0eb6f86e2a802aa0f3e5987e8f6995377426d920900834dd9887d09e582383a93",
   "display_name": "Python 3.8.5 64-bit ('nlp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08539714529945e89b53eab0ac97b32f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bd6509fd092475089975b43065992dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e920fa8938da488aa7341ff02ea3336b",
      "placeholder": "​",
      "style": "IPY_MODEL_d65a5a8f8dd7443baee8d268f2265cbe",
      "value": " 4827/4827 [00:00&lt;00:00, 9229.05it/s]"
     }
    },
    "0d95617ece614abbb4d46b672bb9687d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94c61c9a1afc4d1a810f57b678ea5d8c",
       "IPY_MODEL_8a8e0c6344174c0e82b4a6f11d38a20c"
      ],
      "layout": "IPY_MODEL_08539714529945e89b53eab0ac97b32f"
     }
    },
    "0e920d8c41974bdfac1d58fb46cf71ba": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ba47209576c4387a902abc5b0dbe180": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1c1da5ccfc914b28b5a800e82aec22de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2069ac0814074778bbc0df17f73c28be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f4049cce26948a7936965eac7644dd4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a9342199b414592b74613ff84a3e884": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "415df3189aca4408b4a526fb7109ca11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43d75ca086e44329b0a00d4c4272b78e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "495381cf2be845bba2b305e31b571cf2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a48f25aef0f475fbae1944fbf9a4d05": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4dbc27e6aef24580b9aa7c78386133c8",
       "IPY_MODEL_0bd6509fd092475089975b43065992dd"
      ],
      "layout": "IPY_MODEL_ef3d223156da417d92125c64b4c15764"
     }
    },
    "4dbc27e6aef24580b9aa7c78386133c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5d5bdf4c71e4d78a37e7bf24f3c2723",
      "max": 4827,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_75c212b98d6d4eaea9deb68623d4d859",
      "value": 4827
     }
    },
    "4ee4c46636de4a62852f436939881519": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53635f370ae047d7be069cf8cb322dd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ad0c0f15c214df4b0133928f5cde58e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "636ac053b5dc498ca449c119d9ef9135": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7ab9cc7d5ff648c7a24cbb92a5982a4b",
       "IPY_MODEL_7f0ee4bb7bc2439495d6568f2337c460"
      ],
      "layout": "IPY_MODEL_43d75ca086e44329b0a00d4c4272b78e"
     }
    },
    "68649099ea1540058a383a0fd22650f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "73eac1d1a3fb423fb3f43c7ddd85db8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e920d8c41974bdfac1d58fb46cf71ba",
      "placeholder": "​",
      "style": "IPY_MODEL_83833eeed95b4a3d834cbd357c18a8bf",
      "value": " 6579/6579 [00:00&lt;00:00, 7927.81it/s]"
     }
    },
    "74aa40cf109f4b6ebf7e2ef677e2c40d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1c1da5ccfc914b28b5a800e82aec22de",
      "placeholder": "​",
      "style": "IPY_MODEL_e60e3d7789bd4bb19f5652254048999a",
      "value": " 48309/48309 [00:29&lt;00:00, 1207.64it/s]"
     }
    },
    "75c212b98d6d4eaea9deb68623d4d859": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7ab9cc7d5ff648c7a24cbb92a5982a4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c88edb55a7443ec84d58cf920823ebc",
      "max": 6579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68649099ea1540058a383a0fd22650f0",
      "value": 6579
     }
    },
    "7bba134079cf4465b3c5df28452c2cde": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f0ee4bb7bc2439495d6568f2337c460": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be6e59d759fd47909dc6b1705bb7d03a",
      "placeholder": "​",
      "style": "IPY_MODEL_eb3a3002e9b74d258b276824d215c465",
      "value": " 6579/6579 [00:00&lt;00:00, 7470.78it/s]"
     }
    },
    "825afd3ab8404f0e92a4d38367db8427": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ad0c0f15c214df4b0133928f5cde58e",
      "placeholder": "​",
      "style": "IPY_MODEL_3a9342199b414592b74613ff84a3e884",
      "value": " 48309/48309 [00:37&lt;00:00, 907.68it/s]"
     }
    },
    "83833eeed95b4a3d834cbd357c18a8bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84dca6a666244fd2bf0760567d2e9c9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8578c2da68c44971a4869a5e37a3d171",
      "placeholder": "​",
      "style": "IPY_MODEL_1ba47209576c4387a902abc5b0dbe180",
      "value": " 28/125 [01:07&lt;03:25,  2.12s/it]"
     }
    },
    "8578c2da68c44971a4869a5e37a3d171": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8952810a0e2e4383ba656e6310c29710": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a8e0c6344174c0e82b4a6f11d38a20c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2069ac0814074778bbc0df17f73c28be",
      "placeholder": "​",
      "style": "IPY_MODEL_7bba134079cf4465b3c5df28452c2cde",
      "value": " 4827/4827 [00:00&lt;00:00, 9685.53it/s]"
     }
    },
    "8ee21f1c0ac64447974a90da531497cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94c61c9a1afc4d1a810f57b678ea5d8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f4049cce26948a7936965eac7644dd4",
      "max": 4827,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8d4c75c65ab49208d7837b4b8721db5",
      "value": 4827
     }
    },
    "9c88edb55a7443ec84d58cf920823ebc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2f112a8eb40404abcd9ee035e65fec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 22%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_495381cf2be845bba2b305e31b571cf2",
      "max": 125,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c61c126366334f5382fac34f45f0fde9",
      "value": 28
     }
    },
    "a7fef9d40b9444e2866e33b02fb9dce5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "abad7cb634924003be6e261593ba4c19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b432b77c9bc243fc97f15a5b843d76d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ecc1c611a9f445be8386c6078ba2f2b6",
       "IPY_MODEL_73eac1d1a3fb423fb3f43c7ddd85db8f"
      ],
      "layout": "IPY_MODEL_53635f370ae047d7be069cf8cb322dd2"
     }
    },
    "be6e59d759fd47909dc6b1705bb7d03a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2da6ccaedc34c428d2f7659d32816b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5ba907b448b47609ed8ffc5e0486320": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c61c126366334f5382fac34f45f0fde9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d65a5a8f8dd7443baee8d268f2265cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d9b249d0569c4463a01b2f4e9613266f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a2f112a8eb40404abcd9ee035e65fec9",
       "IPY_MODEL_84dca6a666244fd2bf0760567d2e9c9c"
      ],
      "layout": "IPY_MODEL_4ee4c46636de4a62852f436939881519"
     }
    },
    "ddf2a13c15a2417e9d87b66d02604519": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2da6ccaedc34c428d2f7659d32816b9",
      "max": 48309,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a7fef9d40b9444e2866e33b02fb9dce5",
      "value": 48309
     }
    },
    "e490f93cd74141679e29d16bbe300e74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ddf2a13c15a2417e9d87b66d02604519",
       "IPY_MODEL_825afd3ab8404f0e92a4d38367db8427"
      ],
      "layout": "IPY_MODEL_415df3189aca4408b4a526fb7109ca11"
     }
    },
    "e60e3d7789bd4bb19f5652254048999a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8d4c75c65ab49208d7837b4b8721db5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e920fa8938da488aa7341ff02ea3336b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb3a3002e9b74d258b276824d215c465": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecc1c611a9f445be8386c6078ba2f2b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5ba907b448b47609ed8ffc5e0486320",
      "max": 6579,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb0a5046440f4af4a5e339cd6edcf0d0",
      "value": 6579
     }
    },
    "edda3abe1a4b4eaa853539f3a62b0e61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f71ae15e051e4f719c79d247e3465324",
       "IPY_MODEL_74aa40cf109f4b6ebf7e2ef677e2c40d"
      ],
      "layout": "IPY_MODEL_8ee21f1c0ac64447974a90da531497cc"
     }
    },
    "ef3d223156da417d92125c64b4c15764": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5d5bdf4c71e4d78a37e7bf24f3c2723": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f71ae15e051e4f719c79d247e3465324": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8952810a0e2e4383ba656e6310c29710",
      "max": 48309,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_abad7cb634924003be6e261593ba4c19",
      "value": 48309
     }
    },
    "fb0a5046440f4af4a5e339cd6edcf0d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}